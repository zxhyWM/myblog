{"pages":[{"title":"分类","text":"","link":"/categories/index.html"},{"title":"分类","text":"","link":"/tags/index.html"}],"posts":[{"title":"","text":"Hadoop伪分布式集群部署前言下载链接 jdk-8u231-linux-x64.tar.gz 链接：https://pan.baidu.com/s/1vNTHh4LzwXpqg82oDnG87A?pwd=8zsh 提取码：8zsh hadoop-3.3.1.tar.gz 清华源Index of /apache/hadoop/common/hadoop-3.3.1 (tsinghua.edu.cn) hadoop-eclipse-plugin-3.3.1.jar 链接：https://pan.baidu.com/s/1FrVyXD_lJlBi7m9paEPBlw?pwd=s2dm 提取码：s2dm eclipse Thank You for Downloading Eclipse | The Eclipse Foundation 1.CentOS 7系统安装本次hadoop伪分布式集群部署共用到三台虚拟机，一台主机master，两台从机slave。为了避免操作不必要的重复性，建议先配置一台主机，在进行克隆即可。 新建虚拟机，自定义安装 选择稍后安装操作系统（如果不是第一次安装，直接选择安装ios的话，会跳过语言选择，直接英文环境） 选择centos7 自己选择文件夹位置和命名 处理器配置自定，宿主机性能高就高点，低就低点，处理器内核总数2差不多 使用NAT模式，一直下一步即可。 创建完成后，开启虚拟机，选择中文环境。 更改三个位置 软件选择带GUI的服务器 安装位置点击完成即可 网络和主机名：主机名自行修改 返回开始安装 root密码可以简单点123456（点击左上角完成两次） 然后等待安装完成，不要忘了勾选许可证 2.NAT网络设计与配置三台虚拟机的ip设计实例： master：192.168.150.70 slave1：192.168.150.71 slave2：192.168.150.72 打开VMware中master中的虚拟网络编辑器 选择VMnet8查看NAT设置 查看网卡 开启虚拟机，以root用户登录，或者自定义用户登录，再赋权限 更改master机的网络设置，个人觉得gedit操作更贴近Windows下的编辑方式，用不惯vim操作的可以试试 1gedit /etc/sysconfig/network-scripts/ifcfg-ens33 修改两个地方，再添加网络信息 BOOTPROTO=static ONBOOT=yes 最后添加自定的网络信息 IPADDR=192.168.150.70（最后一个字节自定，前三位要与前一步虚拟网络配置中的相同） NETMASK=255.255.255.0 GATEWAY=192.168.150.2（前一步nat设置里的一致） DNS1=192.168.150.2（与网卡相同） 保存后退出，在终端输入指令 重启网卡服务 systemctl restart network 输入指令查看是否配置成功 ifconfig 配置成功 3.防火墙配置五步设置 firewall-cmd –state // 查看防火墙状态 systemctl stop firewalld.service // 关闭防火墙 firewall-cmd –state // 再次查看防火墙状态 systemctl disable firewalld.service // 设置开机禁止启动防火墙 systemctl status firewalld // 查看防火墙状态 配置完成后，关机master机，克隆出两台从机slave1、slave2克隆成功后再分别修改ip地址，由于是克隆的，现在的两台slave机的主机名还和master一样，修改主机名多种方法，示例一种 gedit /etc/hostname 在打开的文件里删掉原来的主机名，改成自定的主机名。修改完保存退出，重启虚拟机。 4.虚拟机网络访问4.1虚拟机互联互通在三台虚拟机上修改网络节点映射 gedit /etc/hosts 三台虚拟机上同样的操作，在打开的文件中添加三台虚拟机的ip和主机名 192.168.150.70 master 192.168.150.71 slave1 192.168.150.72 slave2 修改完成后，再进行互联互通操作 为了不手动停止（ctrl+c），只测试互联三次 例如master机 ping slave1 -c 3 ping slave2 -c 3 不报错，测试成功 4.2虚拟机访问外网就是能不能访问互联网，两种方式，ping或者在浏览器里搜索是否成功 例如测试连接百度三次 ping www.baidu.com -c 3 能够访问成功 5.虚拟机SSH免密登录简单来说，ssh可以使一台虚拟机远程登录另一台虚拟机时不需要密码。对于本次Hadoop伪分布式集群分布部署，只要主机master能够实现对其自己以及两台从机slave的ssh即可 步骤：在master机上操作 ssh-keygen -t rsa //生成新密钥，一路回车确认 例如slave1的ssh配置 ssh-copy-id slave1 //输入yes 以及slave1密码 ssh slave1 //测试是否能免密登录，成功的话，会看到master主机名变成了slave1，exit退出 重复类似slave1的ssh配置，来配置slave2和自己 6.JDK环境配置centos7装机自带的jdk，所以先查找出，再删除，删除后再下载安装官网的jdk 以master机为例（==其他两台slave相同操作==），查找出Java的安装路径 which java //查找自带的jdk ls -lr 上一行结果 ls -lrt 上一行结果 这就是Java的安装路径 /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.262.b10-1.el7.x86_64/jre/bin/java 卸载centos自带的jdk rpm -qa | grep java //出现的结果都删除 rpm -e –nodeps 一行的结果 //卸载一行一行的来 对于其他两台slave，自带的jdk都一样，只执行rpm -e –nodeps删除命令即可 下载jdk-8u231-linux-x64.tar.gz 链接：https://pan.baidu.com/s/1vNTHh4LzwXpqg82oDnG87A?pwd=8zsh 提取码：8zsh 将文件上传到虚拟机中，可以通过远程登录软件（例如WinSCPPortable）、VMware自带的共享文件夹操作（最好加入到开机挂载，这样不用每次添加文件夹）、安装了VMware Tools可以直接从桌面拖到虚拟机内（有时候会造成文件损坏，重启或者重新安装一下VMware Tools）、在已经联网的虚拟机内下载 四种方法随便都行，个人使用了共享文件夹方式 占位：以后再写 自定文件存放地址，以本人配置为例，在/opt下新建目录/hadoop，用来放置hadoop、jdk mkdir /opt/hadoop 上传文件之后解压缩，并重命名文件夹，方便之后的指令输入 tar zxvf jdk-8u231-linux-x64.tar.gz所在路径 -C /opt/hadoop mv jdk1.8.0_231 jdk1.8 修改系统环境变量==（三台都要）== gedit /etc/profile //用于设置系统级的环境变量和启动程序，在这个文件下配置会对所有用户生效。 在最后添加 1234JAVA_HOME=/opt/hadoop/jdk1.8JRE_HOME=/opt/hadoop/jdk1.8/jrePATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/binCLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib 应用变量（只要修改了配置文件，不应用变量是不会成功的） source /etc/profile 修改bashrc文件 gedit /.bashrc //用户级的位于/.bashrc，仅对当前用户生效。 在最后添加 1234export JAVA_HOME=/opt/hadoop/jdk1.8export JRE_HOME=$JAVA_HOME/jreexport PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/binexport CLASSPATH=.:$CLASSPATH:$JAVA_HOME/lib:$JRE_HOME/lib 应用变量 source ~/.bashrc 查看java版本，有的话就是配置成功 java -version 7.Hadoop环境配置下载hadoop-3.3.1.tar.gz 清华源Index of /apache/hadoop/common/hadoop-3.3.1 (tsinghua.edu.cn) 和上一步下载解压jdk的步骤一样 上传文件之后解压缩，并重命名文件夹，方便之后的指令输入 tar zxvf hadoop-3.3.1.tar.gz所在路径 -C /opt/hadoop mv hadoop-3.3.1 hadoop3.3.1 修改系统环境变量==（三台都要）== gedit /etc/profile 在最后添加 12345export HDFS_NAMENODE_USER=rootexport HDFS_DATANODE_USER=rootexport HDFS_SECONDARYNAMENODE_USER=rootexport YARN_RESOURCEMANAGER_USER=rootexport YARN_NODEMANAGER_USER=root 应用变量（只要修改了配置文件，不应用变量是不会成功的） source /etc/profile 修改bashrc文件 gedit /.bashrc //用户级的位于/.bashrc，仅对当前用户生效。 在最后添加 12345678export HADOOP_HOME=/opt/hadoop/hadoop3.3.1export PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATHexport HADOOP_MAPRED_HOME=$HADOOP_HOMEexport HADOOP_COMMON_HOME=$HADOOP_HOMEexport HADOOP_HDFS_HOME=$HADOOP_HOMEexport YARN_HOME=$HADOOP_HOMEexport HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/nativeexport HADOOP_INSTALL=$HADOOP_HOME 应用变量 source ~/.bashrc 8.Hadoop集群设计与部署至此，jdk和hadoop的环境变量配置完毕，接下来配置hadoop文件 先在/opt/hadoop/hadoop3.3.1下新建几个目录（为什么？纯粹是后面报错发现是没有目录，现在穿越回来建目录！！！） cd /opt/hadoop/hadoop3.3.1/ mkdir /tmp mkdir /tmp/dfs mkdir /tmp/dfs/name mkdir /tmp/dfs/data mkdir /logs 进入配置目录配置文件，共需配置六个文件（core-site.xml、hdfs-site.xml、mapred-site.xml、yarn-site.xml、hadoop-env.sh、workers） cd /opt/hadoop/hadoop3.3.1/etc/hadoop 配置core-site.xml 12345678910111213&lt;configuration&gt; &lt;!-- 文件系统地址，代码中设置连接配置时要用 --&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://master:9000&lt;/value&gt; &lt;/property&gt; &lt;!-- 临时存放数据的目录 --&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/opt/hadoop/hadoop3.3.1/tmp&lt;/value&gt; &lt;description&gt;Abase for other temporary dorectories.&lt;/description&gt; &lt;/property&gt;&lt;/configuration&gt; 配置hdfs-site.xml 本次master只是作为名字节点，不作为数据节点，dfs.replication一般设为3，但如果slave节点少于3，则等于slave节点数量+master节点，或只是slave节点数量，要与前面slaves相对应 12345678910111213141516171819202122&lt;configuration&gt; &lt;!-- NameNode存储元数据信息的路径，实际工作中，一般先确定磁盘的挂载目录，然后多个目录用，进行分割 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; &lt;value&gt;master:9870&lt;/value&gt; &lt;/property&gt; &lt;!-- 是个client参数，即node level参数，需要在每台datanode上设置 --&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;3&lt;/value&gt; &lt;/property&gt; &lt;!-- 保存FsImage镜像的目录，作用是存放hadoop的名称节点namenode里的metadata --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;file:/opt/hadoop/hadoop3.3.1/tmp/dfs/name&lt;/value&gt; &lt;/property&gt; &lt;!-- 存放HDFS文件系统数据文件的目录，作用是存放hadoop的数据节点datanode里的多个数据块 --&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;file:/opt/hadoop/hadoop3.3.1/tmp/dfs/data&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 配置mapred-site.xml 1234567891011121314151617&lt;configuration&gt; &lt;!-- 取值local、classic或yarn其中之一，如果不是yarn，则不会使用yarn集群来实现资源的分配 --&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; &lt;!-- 定义历史服务器的地址和端口，通过历史服务器查看已经运行完的Mapreduce作业记录 --&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt; &lt;value&gt;master:10020&lt;/value&gt; &lt;/property&gt; &lt;!-- 定义历史服务器web应用访问的地址和端口 --&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt; &lt;value&gt;master:19888&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 配置yarn-site.xml 12345678910111213141516171819202122232425262728293031323334353637&lt;configuration&gt; &lt;!-- 通过该配置项，用户可以自定义一些服务，例如Map-Reduce的shuffle功能就是采用这种方式实现的，这样就可以在NodeManager上扩展自己的服务 --&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;!-- RM提供NodeManager的地址。NodeManager通过该地址向RM汇报心跳，领取任务等 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt; &lt;value&gt;master:8031&lt;/value&gt; &lt;/property&gt; &lt;!-- ResourceManager（以下简称RM） 提供客户端访问的地址。客户端通过该地址向RM提交应用程序，杀死应用程序等 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt; &lt;value&gt;master:8032&lt;/value&gt; &lt;/property&gt; &lt;!-- RM提供给ApplicationMaster的访问地址。ApplicationMaster同通过该地址向RM申请资源、释放资源等 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt; &lt;value&gt;master:8030&lt;/value&gt; &lt;/property&gt; &lt;!-- RM对web服务提供地址。用户可通过该地址在浏览器中查看集群各类信息 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt; &lt;value&gt;master:8088&lt;/value&gt; &lt;/property&gt; &lt;!-- 是否启用日志聚集功能 --&gt; &lt;property&gt; &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- 日志服务器的地址 --&gt; &lt;property&gt; &lt;name&gt;yarn.log.server.url&lt;/name&gt; &lt;value&gt;http://master:19888/jobhistory/logs/&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 配置hadoop-env.sh，在最后添加 1export JAVA_HOME=/opt/hadoop/jdk1.8 配置workers，添加两台从机的主机名 12slave1slave2 修改完成之后，如果另外两台slave机上还没有hadoop，将master机上的hadoop3.3.1压缩后传送到slave上 如果已经有的话，传送这六个文件替换原来的文件 为了简单方便，两台slave机上hadoop位置和master机上相同 打压缩包方式： master机上压缩hadoop3.3.1文件（在/opt/hadoop下） tar -zcf ./hadoop-master.tar.gz ./hadoop3.3.1 master机传送压缩包到slave scp ./hadoop-master.tar.gz slave1:/opt/hadoop scp ./hadoop-master.tar.gz slave2:/opt/hadoop 分别在两台slave上进入到压缩包目录（/opt/hadoop）解压 tar zxvf hadoop-master.tar.gz -C ./ 传送六个文件方式： 在master机/opt/hadoop/hadoop3.3.1/etc/hadoop下，以传送给slave1为例 scp core-site.xml slave1:/opt/hadoop/hadoop3.3.1/etc/hadoop scp hdfs-site.xml slave1:/opt/hadoop/hadoop3.3.1/etc/hadoop scp mapred-site.xml slave1:/opt/hadoop/hadoop3.3.1/etc/hadoop scp yarn-site.xml slave1:/opt/hadoop/hadoop3.3.1/etc/hadoop scp hadoop-env.sh slave1:/opt/hadoop/hadoop3.3.1/etc/hadoop scp workers slave1:/opt/hadoop/hadoop3.3.1/etc/hadoop 现在启动hadoop集群 ==首次==启动hadoop先在三台虚拟机进行格式化（启动hadoop成功之后就不要再格式化了！！！否则会导致数据节点不一致运行不了！！！） hdfs namenode -format 启动hadoop，所有虚拟机都要在线 start-all.sh 如果报错的话 解决方法：三台机子/opt/hadoop/hadoop3.3.1/sbin路径下文件 添加在顶部 12345# start-dfs.sh，stop-dfs.sh插入HDFS_DATANODE_USER=rootHADOOP_SECURE_DN_USER=hdfsHDFS_NAMENODE_USER=rootHDFS_SECONDARYNAMENODE_USER=root 1234# start-yarn.sh，stop-yarn.sh插入YARN_RESOURCEMANAGER_USER=rootHADOOP_SECURE_DN_USER=yarnYARN_NODEMANAGER_USER=root 分别在master机、slave机执行 jps命令 jps master slave 现在可以在浏览器查看 输入网址master:9870（或者ip:9870） 如果网址成功访问，那么hadoop部署成功","link":"/2023/04/08/1/"},{"title":"测试1","text":"zssssbusidaicba","link":"/2023/04/05/%E6%B5%8B%E8%AF%951/"},{"title":"“建站历程总结”","text":"a","link":"/2023/04/05/%E2%80%9C%E5%BB%BA%E7%AB%99%E5%8E%86%E7%A8%8B%E6%80%BB%E7%BB%93%E2%80%9D/"},{"title":"no2","text":"","link":"/2023/04/05/no2/"},{"title":"测试2","text":"","link":"/2023/04/06/%E6%B5%8B%E8%AF%952/"},{"title":"测试new","text":"Hadoop伪分布式集群部署前言下载链接 jdk-8u231-linux-x64.tar.gz 链接：https://pan.baidu.com/s/1vNTHh4LzwXpqg82oDnG87A?pwd=8zsh 提取码：8zsh hadoop-3.3.1.tar.gz 清华源Index of /apache/hadoop/common/hadoop-3.3.1 (tsinghua.edu.cn) hadoop-eclipse-plugin-3.3.1.jar 链接：https://pan.baidu.com/s/1FrVyXD_lJlBi7m9paEPBlw?pwd=s2dm 提取码：s2dm eclipse Thank You for Downloading Eclipse | The Eclipse Foundation 1.CentOS 7系统安装本次hadoop伪分布式集群部署共用到三台虚拟机，一台主机master，两台从机slave。为了避免操作不必要的重复性，建议先配置一台主机，在进行克隆即可。 新建虚拟机，自定义安装 选择稍后安装操作系统（如果不是第一次安装，直接选择安装ios的话，会跳过语言选择，直接英文环境） 选择centos7 自己选择文件夹位置和命名 处理器配置自定，宿主机性能高就高点，低就低点，处理器内核总数2差不多 使用NAT模式，一直下一步即可。 创建完成后，开启虚拟机，选择中文环境。 更改三个位置 软件选择带GUI的服务器 安装位置点击完成即可 网络和主机名：主机名自行修改 返回开始安装 root密码可以简单点123456（点击左上角完成两次） 然后等待安装完成，不要忘了勾选许可证 2.NAT网络设计与配置三台虚拟机的ip设计实例： master：192.168.150.70 slave1：192.168.150.71 slave2：192.168.150.72 打开VMware中master中的虚拟网络编辑器 选择VMnet8查看NAT设置 查看网卡 开启虚拟机，以root用户登录，或者自定义用户登录，再赋权限 更改master机的网络设置，个人觉得gedit操作更贴近Windows下的编辑方式，用不惯vim操作的可以试试 1gedit /etc/sysconfig/network-scripts/ifcfg-ens33 修改两个地方，再添加网络信息 BOOTPROTO=static ONBOOT=yes 最后添加自定的网络信息 IPADDR=192.168.150.70（最后一个字节自定，前三位要与前一步虚拟网络配置中的相同） NETMASK=255.255.255.0 GATEWAY=192.168.150.2（前一步nat设置里的一致） DNS1=192.168.150.2（与网卡相同） 保存后退出，在终端输入指令 重启网卡服务 systemctl restart network 输入指令查看是否配置成功 ifconfig 配置成功 3.防火墙配置五步设置 firewall-cmd –state // 查看防火墙状态 systemctl stop firewalld.service // 关闭防火墙 firewall-cmd –state // 再次查看防火墙状态 systemctl disable firewalld.service // 设置开机禁止启动防火墙 systemctl status firewalld // 查看防火墙状态 配置完成后，关机master机，克隆出两台从机slave1、slave2克隆成功后再分别修改ip地址，由于是克隆的，现在的两台slave机的主机名还和master一样，修改主机名多种方法，示例一种 gedit /etc/hostname 在打开的文件里删掉原来的主机名，改成自定的主机名。修改完保存退出，重启虚拟机。 4.虚拟机网络访问4.1虚拟机互联互通在三台虚拟机上修改网络节点映射 gedit /etc/hosts 三台虚拟机上同样的操作，在打开的文件中添加三台虚拟机的ip和主机名 192.168.150.70 master 192.168.150.71 slave1 192.168.150.72 slave2 修改完成后，再进行互联互通操作 为了不手动停止（ctrl+c），只测试互联三次 例如master机 ping slave1 -c 3 ping slave2 -c 3 不报错，测试成功 4.2虚拟机访问外网就是能不能访问互联网，两种方式，ping或者在浏览器里搜索是否成功 例如测试连接百度三次 ping www.baidu.com -c 3 能够访问成功 5.虚拟机SSH免密登录简单来说，ssh可以使一台虚拟机远程登录另一台虚拟机时不需要密码。对于本次Hadoop伪分布式集群分布部署，只要主机master能够实现对其自己以及两台从机slave的ssh即可 步骤：在master机上操作 ssh-keygen -t rsa //生成新密钥，一路回车确认 例如slave1的ssh配置 ssh-copy-id slave1 //输入yes 以及slave1密码 ssh slave1 //测试是否能免密登录，成功的话，会看到master主机名变成了slave1，exit退出 重复类似slave1的ssh配置，来配置slave2和自己 6.JDK环境配置centos7装机自带的jdk，所以先查找出，再删除，删除后再下载安装官网的jdk 以master机为例（==其他两台slave相同操作==），查找出Java的安装路径 which java //查找自带的jdk ls -lr 上一行结果 ls -lrt 上一行结果 这就是Java的安装路径 /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.262.b10-1.el7.x86_64/jre/bin/java 卸载centos自带的jdk rpm -qa | grep java //出现的结果都删除 rpm -e –nodeps 一行的结果 //卸载一行一行的来 对于其他两台slave，自带的jdk都一样，只执行rpm -e –nodeps删除命令即可 下载jdk-8u231-linux-x64.tar.gz 链接：https://pan.baidu.com/s/1vNTHh4LzwXpqg82oDnG87A?pwd=8zsh 提取码：8zsh 将文件上传到虚拟机中，可以通过远程登录软件（例如WinSCPPortable）、VMware自带的共享文件夹操作（最好加入到开机挂载，这样不用每次添加文件夹）、安装了VMware Tools可以直接从桌面拖到虚拟机内（有时候会造成文件损坏，重启或者重新安装一下VMware Tools）、在已经联网的虚拟机内下载 四种方法随便都行，个人使用了共享文件夹方式 占位：以后再写 自定文件存放地址，以本人配置为例，在/opt下新建目录/hadoop，用来放置hadoop、jdk mkdir /opt/hadoop 上传文件之后解压缩，并重命名文件夹，方便之后的指令输入 tar zxvf jdk-8u231-linux-x64.tar.gz所在路径 -C /opt/hadoop mv jdk1.8.0_231 jdk1.8 修改系统环境变量==（三台都要）== gedit /etc/profile //用于设置系统级的环境变量和启动程序，在这个文件下配置会对所有用户生效。 在最后添加 1234JAVA_HOME=/opt/hadoop/jdk1.8JRE_HOME=/opt/hadoop/jdk1.8/jrePATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/binCLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib 应用变量（只要修改了配置文件，不应用变量是不会成功的） source /etc/profile 修改bashrc文件 gedit /.bashrc //用户级的位于/.bashrc，仅对当前用户生效。 在最后添加 1234export JAVA_HOME=/opt/hadoop/jdk1.8export JRE_HOME=$JAVA_HOME/jreexport PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/binexport CLASSPATH=.:$CLASSPATH:$JAVA_HOME/lib:$JRE_HOME/lib 应用变量 source ~/.bashrc 查看java版本，有的话就是配置成功 java -version 7.Hadoop环境配置下载hadoop-3.3.1.tar.gz 清华源Index of /apache/hadoop/common/hadoop-3.3.1 (tsinghua.edu.cn) 和上一步下载解压jdk的步骤一样 上传文件之后解压缩，并重命名文件夹，方便之后的指令输入 tar zxvf hadoop-3.3.1.tar.gz所在路径 -C /opt/hadoop mv hadoop-3.3.1 hadoop3.3.1 修改系统环境变量==（三台都要）== gedit /etc/profile 在最后添加 12345export HDFS_NAMENODE_USER=rootexport HDFS_DATANODE_USER=rootexport HDFS_SECONDARYNAMENODE_USER=rootexport YARN_RESOURCEMANAGER_USER=rootexport YARN_NODEMANAGER_USER=root 应用变量（只要修改了配置文件，不应用变量是不会成功的） source /etc/profile 修改bashrc文件 gedit /.bashrc //用户级的位于/.bashrc，仅对当前用户生效。 在最后添加 12345678export HADOOP_HOME=/opt/hadoop/hadoop3.3.1export PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATHexport HADOOP_MAPRED_HOME=$HADOOP_HOMEexport HADOOP_COMMON_HOME=$HADOOP_HOMEexport HADOOP_HDFS_HOME=$HADOOP_HOMEexport YARN_HOME=$HADOOP_HOMEexport HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/nativeexport HADOOP_INSTALL=$HADOOP_HOME 应用变量 source ~/.bashrc 8.Hadoop集群设计与部署至此，jdk和hadoop的环境变量配置完毕，接下来配置hadoop文件 先在/opt/hadoop/hadoop3.3.1下新建几个目录（为什么？纯粹是后面报错发现是没有目录，现在穿越回来建目录！！！） cd /opt/hadoop/hadoop3.3.1/ mkdir /tmp mkdir /tmp/dfs mkdir /tmp/dfs/name mkdir /tmp/dfs/data mkdir /logs 进入配置目录配置文件，共需配置六个文件（core-site.xml、hdfs-site.xml、mapred-site.xml、yarn-site.xml、hadoop-env.sh、workers） cd /opt/hadoop/hadoop3.3.1/etc/hadoop 配置core-site.xml 12345678910111213&lt;configuration&gt; &lt;!-- 文件系统地址，代码中设置连接配置时要用 --&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://master:9000&lt;/value&gt; &lt;/property&gt; &lt;!-- 临时存放数据的目录 --&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/opt/hadoop/hadoop3.3.1/tmp&lt;/value&gt; &lt;description&gt;Abase for other temporary dorectories.&lt;/description&gt; &lt;/property&gt;&lt;/configuration&gt; 配置hdfs-site.xml 本次master只是作为名字节点，不作为数据节点，dfs.replication一般设为3，但如果slave节点少于3，则等于slave节点数量+master节点，或只是slave节点数量，要与前面slaves相对应 12345678910111213141516171819202122&lt;configuration&gt; &lt;!-- NameNode存储元数据信息的路径，实际工作中，一般先确定磁盘的挂载目录，然后多个目录用，进行分割 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; &lt;value&gt;master:9870&lt;/value&gt; &lt;/property&gt; &lt;!-- 是个client参数，即node level参数，需要在每台datanode上设置 --&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;3&lt;/value&gt; &lt;/property&gt; &lt;!-- 保存FsImage镜像的目录，作用是存放hadoop的名称节点namenode里的metadata --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;file:/opt/hadoop/hadoop3.3.1/tmp/dfs/name&lt;/value&gt; &lt;/property&gt; &lt;!-- 存放HDFS文件系统数据文件的目录，作用是存放hadoop的数据节点datanode里的多个数据块 --&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;file:/opt/hadoop/hadoop3.3.1/tmp/dfs/data&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 配置mapred-site.xml 1234567891011121314151617&lt;configuration&gt; &lt;!-- 取值local、classic或yarn其中之一，如果不是yarn，则不会使用yarn集群来实现资源的分配 --&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; &lt;!-- 定义历史服务器的地址和端口，通过历史服务器查看已经运行完的Mapreduce作业记录 --&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt; &lt;value&gt;master:10020&lt;/value&gt; &lt;/property&gt; &lt;!-- 定义历史服务器web应用访问的地址和端口 --&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt; &lt;value&gt;master:19888&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 配置yarn-site.xml 12345678910111213141516171819202122232425262728293031323334353637&lt;configuration&gt; &lt;!-- 通过该配置项，用户可以自定义一些服务，例如Map-Reduce的shuffle功能就是采用这种方式实现的，这样就可以在NodeManager上扩展自己的服务 --&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;!-- RM提供NodeManager的地址。NodeManager通过该地址向RM汇报心跳，领取任务等 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt; &lt;value&gt;master:8031&lt;/value&gt; &lt;/property&gt; &lt;!-- ResourceManager（以下简称RM） 提供客户端访问的地址。客户端通过该地址向RM提交应用程序，杀死应用程序等 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt; &lt;value&gt;master:8032&lt;/value&gt; &lt;/property&gt; &lt;!-- RM提供给ApplicationMaster的访问地址。ApplicationMaster同通过该地址向RM申请资源、释放资源等 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt; &lt;value&gt;master:8030&lt;/value&gt; &lt;/property&gt; &lt;!-- RM对web服务提供地址。用户可通过该地址在浏览器中查看集群各类信息 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt; &lt;value&gt;master:8088&lt;/value&gt; &lt;/property&gt; &lt;!-- 是否启用日志聚集功能 --&gt; &lt;property&gt; &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- 日志服务器的地址 --&gt; &lt;property&gt; &lt;name&gt;yarn.log.server.url&lt;/name&gt; &lt;value&gt;http://master:19888/jobhistory/logs/&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 配置hadoop-env.sh，在最后添加 1export JAVA_HOME=/opt/hadoop/jdk1.8 配置workers，添加两台从机的主机名 12slave1slave2 修改完成之后，如果另外两台slave机上还没有hadoop，将master机上的hadoop3.3.1压缩后传送到slave上 如果已经有的话，传送这六个文件替换原来的文件 为了简单方便，两台slave机上hadoop位置和master机上相同 打压缩包方式： master机上压缩hadoop3.3.1文件（在/opt/hadoop下） tar -zcf ./hadoop-master.tar.gz ./hadoop3.3.1 master机传送压缩包到slave scp ./hadoop-master.tar.gz slave1:/opt/hadoop scp ./hadoop-master.tar.gz slave2:/opt/hadoop 分别在两台slave上进入到压缩包目录（/opt/hadoop）解压 tar zxvf hadoop-master.tar.gz -C ./ 传送六个文件方式： 在master机/opt/hadoop/hadoop3.3.1/etc/hadoop下，以传送给slave1为例 scp core-site.xml slave1:/opt/hadoop/hadoop3.3.1/etc/hadoop scp hdfs-site.xml slave1:/opt/hadoop/hadoop3.3.1/etc/hadoop scp mapred-site.xml slave1:/opt/hadoop/hadoop3.3.1/etc/hadoop scp yarn-site.xml slave1:/opt/hadoop/hadoop3.3.1/etc/hadoop scp hadoop-env.sh slave1:/opt/hadoop/hadoop3.3.1/etc/hadoop scp workers slave1:/opt/hadoop/hadoop3.3.1/etc/hadoop 现在启动hadoop集群 ==首次==启动hadoop先在三台虚拟机进行格式化（启动hadoop成功之后就不要再格式化了！！！否则会导致数据节点不一致运行不了！！！） hdfs namenode -format 启动hadoop，所有虚拟机都要在线 start-all.sh 如果报错的话 解决方法：三台机子/opt/hadoop/hadoop3.3.1/sbin路径下文件 添加在顶部 12345# start-dfs.sh，stop-dfs.sh插入HDFS_DATANODE_USER=rootHADOOP_SECURE_DN_USER=hdfsHDFS_NAMENODE_USER=rootHDFS_SECONDARYNAMENODE_USER=root 1234# start-yarn.sh，stop-yarn.sh插入YARN_RESOURCEMANAGER_USER=rootHADOOP_SECURE_DN_USER=yarnYARN_NODEMANAGER_USER=root 分别在master机、slave机执行 jps命令 jps master slave 现在可以在浏览器查看 输入网址master:9870（或者ip:9870） 如果网址成功访问，那么hadoop部署成功","link":"/2023/04/08/%E6%B5%8B%E8%AF%95new/"}],"tags":[],"categories":[]}